{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LE O ARQUIVO CSV\n",
    "fig_size = (10, 6)\n",
    "dataframe = pd.read_csv('/Users/Matheus Carvalho/Downloads/dataset3.csv', header=[0]) # load dataset\n",
    "final_dataframe = dataframe.drop([\"Node\",\"Class\",\"'Flood Status'\",'Average_Delay_Time_Per_Sec'\n",
    "                   ,'Percentage_Of_Lost_Pcaket_Rate','Percentage_Of_Lost_Byte_Rate'\n",
    "                   ,'10-Run-AVG-Drop-Rate','10-Run-AVG-Bandwith-Use','10-Run-Delay',\"'Packet Size_Byte'\"], axis=1)\n",
    "\n",
    "parametros1=['UBR','PDR','FB','PRR','UB','LB','PT','PR','PL','TB','RB']\n",
    "class_names = ['B', \"'P NB'\", 'NB']\n",
    "\n",
    "#NORMALIZAÇÃO DOS DADOS\n",
    "scaler = preprocessing.StandardScaler().fit(final_dataframe.drop([\"'Node Status'\"], axis=1))\n",
    "x_scaled = scaler.transform(final_dataframe.drop(\"'Node Status'\", axis=1))\n",
    "scaled_final_dataframe = pd.DataFrame(x_scaled, index=final_dataframe.index, columns=final_dataframe.columns[:-1])\n",
    "y = final_dataframe[\"'Node Status'\"]\n",
    "scaled_final_dataframe[\"'Node Status'\"]=y\n",
    "\n",
    "#PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x_scaled)\n",
    "principalDf = pd.DataFrame(data=principalComponents\n",
    "                                   , columns=['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([principalDf, dataframe[[\"'Node Status'\"]]], axis=1)\n",
    "plt.figure(figsize=fig_size)\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2']\n",
    "markers = ['o', '*', 'v']\n",
    "sns.lmplot(x='principal component 1',\n",
    "               y='principal component 2',\n",
    "               data=finalDf,\n",
    "          fit_reg=False,\n",
    "          hue=\"'Node Status'\", markers=markers, legend=False, legend_out=False, height=fig_size[1], aspect=fig_size[0]/fig_size[1])\n",
    "\n",
    "plt.legend(class_names, loc=9)\n",
    "plt.xlabel('Principal Component 1', fontsize=15)\n",
    "plt.ylabel('Principal Component 2', fontsize=15)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "#MAPA DE CORRELAÇÃO\n",
    "corr = scaled_final_dataframe.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plt.figure(figsize=fig_size)\n",
    "sns.heatmap(corr, linewidths=.5, mask=mask, xticklabels=parametros1, yticklabels=parametros1, linecolor='white', cmap=\"RdBu_r\", annot=True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#MAPA DE CORRELAÇÃO DE CADA CENÁRIO\n",
    "for attack in class_names:\n",
    "    corr = scaled_final_dataframe.where(dataframe[\"'Node Status'\"] == attack).corr()\n",
    "\n",
    "    plt.figure(figsize=fig_size)\n",
    "    sns.heatmap(corr, linewidths=.5, mask=mask,xticklabels=parametros1, yticklabels=parametros1, linecolor='white', cmap=\"RdBu_r\", annot=True)\n",
    "    plt.title('Correlation only for the ' + attack + ' scenario')\n",
    "\n",
    "#MAPA DE DIFERENTES CORRELAÇÕES DOS CENÁRIOS DE ATAQUES\n",
    "\n",
    "no_attack_corr = scaled_final_dataframe.where(dataframe[\"'Node Status'\"] == 'B').corr()\n",
    "for attack in class_names:\n",
    "    corr = scaled_final_dataframe.where(dataframe[\"'Node Status'\"] == attack).corr()\n",
    "\n",
    "    plt.figure(figsize=fig_size)\n",
    "    sns.heatmap(corr - no_attack_corr, linewidths=.5, mask=mask,xticklabels=parametros1, yticklabels=parametros1, linecolor='white', annot=True, cmap=\"RdBu_r\")\n",
    "    plt.title('Difference from ' + class_names[0] + ' to ' + attack + ' attack')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#LINHA DO TEMPO COM A CORRELAÇÃO\n",
    "\n",
    "steps = [20, 30]\n",
    "samples_per_attack = 60\n",
    "\n",
    "X = []\n",
    "\n",
    "for att in class_names:\n",
    "    for s in range(samples_per_attack):\n",
    "        i = (len(att) * samples_per_attack) + s\n",
    "        samples = scaled_final_dataframe[(scaled_final_dataframe[\"'Node Status'\"] == att)].sample(n=1)\n",
    "        X.append(samples.values[0])\n",
    "\n",
    "\n",
    "correlation_dataframe = pd.DataFrame(data=X, columns=scaled_final_dataframe.columns).corr()\n",
    "\n",
    "X=np.reshape(X,newshape=(len(X),len(X[0])))\n",
    "correlation_dataframe2 = pd.DataFrame(data=X, columns=scaled_final_dataframe.columns)\n",
    "\n",
    "correlations = {}\n",
    "attack_change = {}\n",
    "\n",
    "\n",
    "for step in steps:\n",
    "    correlations[step] = {}\n",
    "    correlations[step]['PL<>PDR'] = []\n",
    "    correlations[step]['PL<>PRR'] = []\n",
    "    attack_change[step] = []\n",
    "    last_attack=\"B\"\n",
    "    for start in range(0, len(correlation_dataframe) - step):\n",
    "        attack_change[step].append(correlation_dataframe.iloc[start + step][\"'Node Status'\"] != last_attack)\n",
    "        last_attack = correlation_dataframe.iloc[start + step][\"'Node Status'\"]\n",
    "        corr = correlation_dataframe.drop([\"'Node Status'\"], axis=1).iloc[start:start + step].corr()\n",
    "        correlations[step]['PL<>PDR'].append(corr['Packet_lost'][\"'Packet Drop Rate'\"])\n",
    "        correlations[step]['PL<>PRR'].append(corr['Packet_lost'][\"'Packet Received  Rate'\"])\n",
    "\n",
    "for step in steps:\n",
    "    plt.figure(figsize=fig_size)\n",
    "    ax1 = sns.lineplot(range(0, len(correlations[step]['PL<>PDR'])), correlations[step]['PL<>PDR'], label='PL / PDR')\n",
    "    ax2 = sns.lineplot(range(0, len(correlations[step]['PL<>PRR'])), correlations[step]['PL<>PRR'], label='PL / PRR')\n",
    "    ax2.lines[0].set_linestyle(\":\")\n",
    "    ax2.lines[0].set_marker(\"o\")\n",
    "    ax2.lines[0].set_markevery(10)\n",
    "    ax2.lines[1].set_linestyle(\"--\")\n",
    "    ax2.lines[1].set_marker(\"s\")\n",
    "    ax2.lines[1].set_markevery(10)\n",
    "\n",
    "    for x, att in enumerate(attack_change[step]):\n",
    "        if att:\n",
    "            plt.axvline(x, color='red', linestyle=':')\n",
    "    plt.xlabel('Number of monitoring samples')\n",
    "    plt.ylabel('Correlation')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#USANDO P DBSCAN\n",
    "\n",
    "X = scaled_final_dataframe[(scaled_final_dataframe[\"'Node Status'\"] == 'B')].drop(\"'Node Status'\", axis=1).values\n",
    "X = correlation_dataframe2[(correlation_dataframe2[\"'Node Status'\"] == 'B')].drop(\"'Node Status'\", axis=1).values\n",
    "\n",
    "labels_true = scaled_final_dataframe[(scaled_final_dataframe[\"'Node Status'\"] == 'B')][\"'Node Status'\"].values\n",
    "labels_true = correlation_dataframe2[(correlation_dataframe2[\"'Node Status'\"] == 'B')][\"'Node Status'\"].values\n",
    "\n",
    "epsilon_configurations = [.1, .5, 1., 1., 2., 3., 4.]\n",
    "min_samples_configurations = [1, 3, 5, 8, 10, 12, 15, 20]\n",
    "\n",
    "values = np.zeros((len(min_samples_configurations), len(epsilon_configurations)))\n",
    "\n",
    "predictors = np.empty((len(min_samples_configurations), len(epsilon_configurations)), dtype=DBSCAN)\n",
    "\n",
    "for idm, min_samples in enumerate(min_samples_configurations):\n",
    "\n",
    "    for ide, epsilon in enumerate(epsilon_configurations):\n",
    "\n",
    "        dbscan = DBSCAN(eps=epsilon, min_samples=min_samples, metric='euclidean')\n",
    "        db = dbscan.fit(X)\n",
    "        labels = db.labels_\n",
    "        values[idm, ide] = (np.sum([1 for label in labels if label == -1]) * 100) / len(X)\n",
    "        predictors[idm, ide] = dbscan\n",
    "\n",
    "plt.figure(figsize=fig_size)\n",
    "sns.heatmap(values, linewidths=.5, linecolor='white', annot=True, cmap=\"RdBu_r\", cbar=False, fmt='.2f')\n",
    "\n",
    "plt.ylabel('$MinPts$')\n",
    "plt.yticks([x + .5 for x in range(0, len(min_samples_configurations))], min_samples_configurations)\n",
    "\n",
    "plt.xlabel('$\\epsilon$')\n",
    "plt.xticks([x + .5 for x in range(0, len(epsilon_configurations))], epsilon_configurations)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "###########################\n",
    "\n",
    "for attack in class_names:\n",
    "    print('\\nresults for attack', attack)\n",
    "\n",
    "    X1 = final_dataframe[(final_dataframe[\"'Node Status'\"] == 'B')].drop(\"'Node Status'\", axis=1).values\n",
    "    X2 = final_dataframe[(final_dataframe[\"'Node Status'\"] == attack)].drop(\"'Node Status'\", axis=1).values[:10]\n",
    "    X = np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "    Y1 = final_dataframe[(final_dataframe[\"'Node Status'\"] == 'B')][\"'Node Status'\"].values\n",
    "    Y2 = final_dataframe[(final_dataframe[\"'Node Status'\"] == attack)][\"'Node Status'\"].values[:10]\n",
    "    labels_true = np.concatenate((Y1, Y2), axis=0)\n",
    "\n",
    "    for epsilon in epsilon_configurations:\n",
    "        print('\\t', epsilon, end='\\t')\n",
    "    print('')\n",
    "\n",
    "    for ide, epsilon in enumerate(epsilon_configurations):\n",
    "        print('\\t(fp, fn) %', end='')\n",
    "    print('')\n",
    "\n",
    "    for idm, min_samples in enumerate(min_samples_configurations):\n",
    "        print(min_samples, end='\\t')\n",
    "\n",
    "        for ide, epsilon in enumerate(epsilon_configurations):\n",
    "\n",
    "            labels = predictors[idm, ide].fit_predict(X)\n",
    "\n",
    "            false_positives = np.sum(\n",
    "                [1 if label == -1 else 0 for true_label, label in zip(labels_true, labels) if true_label == 'B'])\n",
    "            false_negatives = np.sum(\n",
    "                [1 if label > -1 else 0 for true_label, label in zip(labels_true, labels) if true_label != 'B'])\n",
    "\n",
    "            print('%0.2f,' % (false_positives * 100 / len(X)), '%0.2f' % (false_negatives * 100 / len(X)), end='\\t')\n",
    "        print('')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
